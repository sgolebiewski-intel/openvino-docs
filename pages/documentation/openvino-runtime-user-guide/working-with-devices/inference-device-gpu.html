
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />
<meta content="The GPU plugin in the Intel® Distribution of OpenVINO™ toolkit is is an OpenCL based plugin for inference of deep neural networks on Intel® GPus." name="description" />
<meta content="OpenVINO™, OpenVINO Runtime, GPU plugin, Intel GPU, inference, inference device, integrated Intel GPU, discrete Intel GPU, inference precision, f32 data type, f16 data type, bfloat16, u8 data type, i8 data type, u1 data type, FP32, FP32 precision, floating-point data type, FP16 precision, multi-device execution, multi-stream execution, dynamic shapes, preprocessing acceleration, model caching, extensibility, read-write properties, read-only properties, OpenVINO IR, OpenVINO Intermediate Representation, compile model, BATCH, BATCH plugin" name="keywords" />

    <title>GPU Device &#8212; OpenVINO™  documentation</title>
    
    
  <link href="../../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/doxyrest-pygments.css" />
    
  <link rel="preload" as="script" href="../../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <link href="../../../../_static/css/media/favicon.ico" rel="shortcut icon">
    <link rel="stylesheet" href="../../../../_static/css/openvino_sphinx_theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/button.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/input.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/textfield.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/tabs.css" type="text/css" />
    <script src="../../../../_static/js/openvino_sphinx_theme.js"></script>
    <link rel="stylesheet" href="../../../../_static/css/viewer.min.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />

    <script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-datalabels"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/chartjs-plugin-annotation/0.5.7/chartjs-plugin-annotation.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-barchart-background@1.3.0/build/Plugin.Barchart.Background.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-deferred@1"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.3.1/papaparse.min.js"></script>
    <script src="../../../../_static/js/viewer.min.js"></script>
    <script src="/assets/versions_raw.js"></script>

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/tabs.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/js/custom.js"></script>
    <script src="../../../../_static/js/graphs.js"></script>
    <script src="../../../../_static/js/graphs_ov_tf.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script src="../../../../_static/target-highlight.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <link rel="canonical" href="https://docs.openvino.ai/latest/pages/documentation/openvino-runtime-user-guide/working-with-devices/inference-device-gpu.html" />
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Remote Tensor API of GPU Plugin" href="inference-device-gpu/remote-tensor-gpu.html" />
    <link rel="prev" title="CPU Device" href="inference-device-cpu.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
      <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../../../index.html">
  <img src="../../../../_static/logo.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../get-started-guide.html">
  Get Started
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../../documentation.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../tutorials.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../api/api_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../model_zoo.html">
  Model Zoo
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../resources.html">
  Resources
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/openvinotoolkit/openvino" rel="noopener" target="_blank" title="GitHub">
            <span><i class="sst-github"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
</ul>
      </div>
      
      <div class="navbar-end-item">
        
<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="version-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"></button>
  <div class="dropdown-menu" aria-labelledby="version-selector">
  </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        

<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="language-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">English</button>
  <div class="dropdown-menu" aria-labelledby="language-selector">
    
      
        <a class="dropdown-item font-weight-bold" href="/openvino-docs/index.html">English</a>
      
    
      
        <a  class="dropdown-item" href="/cn/openvino-docs/index.html">Chinese</a>
      
    
  </div>
</div>

      </div>
      
    </div>
  </div>
</div>
        <div id="collapse-nav-wrapper" class="container-xl">
          <button id="collapse-nav" class="button bttn-prm button-size-m" type="button" data-toggle="collapse" data-target="#nav-tree" aria-expanded="false" aria-controls="nav-tree">
            Documentation navigation <i class="fas fa-chevron-down"></i>
          </button>
        </div>
      </nav>
      <div class="transition-banner container-fluid alert alert-info alert-dismissible fade show" role="alert">
        <p>OpenVINO 2022.1 introduces a new version of OpenVINO API (API 2.0). For more information on the changes and transition steps, see the <a href="https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html">transition guide</a></p>
        <button type="button" class="close" data-dismiss="alert" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
    </div>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar" id="nav-tree"><form class="searchForm bd-search d-flex align-items-center" action="../../../../search.html" method="get">
    <i class="icon fas fa-search"></i>
    <input type="search" class="form-control" name="query" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  API 2.0
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../api-2.0-transition.html">
   OpenVINO™ API 2.0 Transition Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../api-2.0-transition/api-2.0-deployment.html">
     Installation &amp; Deployment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../api-2.0-transition/api-2.0-inference-pipeline.html">
     Inference Pipeline
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../api-2.0-transition/api-2.0-configure-devices.html">
     Configuring Devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../api-2.0-transition/api-2.0-preprocessing.html">
     Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../api-2.0-transition/api-2.0-model-creation.html">
     Model Creation in OpenVINO™ Runtime
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Converting and Preparing Models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../model-processing.html">
   Introduction to Model Processing
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../converting-models-with-model-optimizer.html">
   Converting Models with Model Optimizer
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../converting-models-with-model-optimizer/input-shapes.html">
     Setting Input Shapes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../converting-models-with-model-optimizer/cutting-model-with-model-optimizer.html">
     Cutting Off Parts of a Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../converting-models-with-model-optimizer/additional-optimization-use-cases.html">
     Embedding Preprocessing Computation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../converting-models-with-model-optimizer/fp16-compression-with-model-optimizer.html">
     Compressing a Model to FP16
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../converting-models-with-model-optimizer/converting-tensorflow-model-with-model-optimizer.html">
     Converting a TensorFlow Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../converting-models-with-model-optimizer/converting-onnx-model-with-model-optimizer.html">
     Converting an ONNX Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../converting-models-with-model-optimizer/converting-pytorch-model.html">
     Converting a PyTorch Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../converting-models-with-model-optimizer/converting-paddlepaddle-model-with-model-optimizer.html">
     Converting a PaddlePaddle Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../converting-models-with-model-optimizer/converting-mxnet-model-with-model-optimizer.html">
     Converting an MXNet Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../converting-models-with-model-optimizer/converting-caffe-model-with-model-optimizer.html">
     Converting a Caffe Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../converting-models-with-model-optimizer/converting-kaldi-model-with-model-optimizer.html">
     Converting a Kaldi Model
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials.html">
     Model Conversion Tutorials
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-tensorflow-attention-ocr-model.html">
       Convert a TensorFlow Attention OCR Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-tensorflow-bert-model.html">
       Convert a TensorFlow BERT Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-tensorflow-crnn-model.html">
       Convert a TensorFlow CRNN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-tensorflow-deepspeech-model.html">
       Convert a TensorFlow DeepSpeech Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-tensorflow-efficientdet-model.html">
       Convert TensorFlow EfficientDet Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-tensorflow-facenet-model.html">
       Convert TensorFlow FaceNet Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-tensorflow-gnmt-model.html">
       Convert a TensorFlow GNMT Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-tensorflow-language-model-on-billion-word-benchmark.html">
       Convert a TensorFlow Language Model on One Billion Word Benchmark
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-tensorflow-ncf-model.html">
       Convert a TensorFlow Neural Collaborative Filtering Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-tensorflow-object-detection-api-model.html">
       Convert TensorFlow Object Detection API Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-tensorflow-retinanet-model.html">
       Convert a TensorFlow RetinaNet Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-tensorflow-slim-library-models.html">
       Convert TensorFlow Slim Image Classification Model Library Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-tensorflow-wide-and-deep-family-models.html">
       Convert TensorFlow Wide and Deep Family Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-tensorflow-xlnet-model.html">
       Convert a TensorFlow XLNet Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-tensorflow-yolo-models.html">
       Convert TensorFlow YOLO Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-onnx-faster-r-cnn-model.html">
       Convert an ONNX Faster R-CNN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-onnx-gpt-2-model.html">
       Convert an ONNX GPT-2 Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-onnx-mask-r-cnn-model.html">
       Convert an ONNX Mask R-CNN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-pytorch-bert-ner-model.html">
       Convert a PyTorch BERT-NER Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-pytorch-cascade-rcn-r-101-model.html">
       Convert a PyTorch Cascade RCNN R-101 Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-pytorch-f3net-model.html">
       Convert a PyTorch F3Net Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-pytorch-quartznet-model.html">
       Convert a PyTorch QuartzNet Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-pytorch-rcan-model.html">
       Convert a PyTorch RCAN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-pytorch-rnn-t-model.html">
       Convert a PyTorch RNN-T Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-pytorch-yolact-model.html">
       Convert a PyTorch YOLACT Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-mxnet-gluoncv-models.html">
       Convert MXNet GluonCV Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-mxnet-style-transfer-model.html">
       Convert an MXNet Style Transfer Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../converting-models-with-model-optimizer/convert-model-tutorials/converting-kaldi-aspire-chain-tdnn-model.html">
       Convert a Kaldi ASpIRE Chain Time Delay Neural Network (TDNN) Model
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../converting-models-with-model-optimizer/faq-model-optimizer.html">
     Model Optimizer Frequently Asked Questions
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Optimization and Performance
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../performance-optimization.html">
   Introduction to Performance Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../getting-performance-numbers.html">
   Getting Performance Numbers
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../model-optimization-guide.html">
   Model Optimization Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization.html">
     Optimizing Models Post-training
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/quantizing-model.html">
       Quantizing Models
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
      <label for="toctree-checkbox-6">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/quantizing-model/default-quantization-algorithm.html">
         DefaultQuantization Parameters
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/accuracy-aware-quantization.html">
       Quantizing Models with Accuracy Control
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
      <label for="toctree-checkbox-7">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/accuracy-aware-quantization/accuracy-aware-quantization-algorithm.html">
         AccuracyAwareQuantization Parameters
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/best-practices.html">
       Post-Training Quantization Best Practices
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
      <label for="toctree-checkbox-8">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/best-practices/saturation-issue.html">
         Saturation Issue
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/pot-api.html">
       Post-training Optimization Tool API
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/command-line-interface.html">
       POT Command-line Interface
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
      <label for="toctree-checkbox-9">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/command-line-interface/simplified-mode.html">
         Optimization in Simplified Mode
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/command-line-interface/configuration-file.html">
         Configuration File Description
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/examples.html">
       Examples
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
      <label for="toctree-checkbox-10">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4 has-children">
        <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/examples/api-examples.html">
         POT API Examples
        </a>
        <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
        <label for="toctree-checkbox-11">
         <i class="fas fa-chevron-down">
         </i>
        </label>
        <ul>
         <li class="toctree-l5">
          <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/examples/api-examples/quantizing-image-classification-model.html">
           Quantizing Image Classification Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/examples/api-examples/quantizing-with-accuracy-control.html">
           Quantizing with Accuracy Control
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/examples/api-examples/quantizing-face-detection-model.html">
           Quantizing Face Detection Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/examples/api-examples/quantizing-segmentation-model.html">
           Quantizing Semantic Segmentation Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/examples/api-examples/quantizing-3d-segmentation-model.html">
           Quantizing 3D Segmentation Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/examples/api-examples/quantizing-for-gna-device.html">
           Quantizing for GNA Device
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/examples/command-line-example.html">
         Command-line Interface Example
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../model-optimization-guide/post-training-model-optimization/post-training-optimization-tool-faq.html">
       Post-training Optimization Tool FAQ
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../model-optimization-guide/tmo-introduction.html">
     Optimizing Models at Training Time
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
    <label for="toctree-checkbox-12">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../model-optimization-guide/tmo-introduction/qat-introduction.html">
       Quantization-aware Training (QAT)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../model-optimization-guide/tmo-introduction/filter-pruning.html">
       Filter Pruning of Convolutional Models
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../model-optimization-guide/experimental-protecting-model.html">
     Experimental: Protecting Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../runtime-inference-optimizations.html">
   Runtime Inference Optimizations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../runtime-inference-optimizations/general-optimizations.html">
     General Optimizations
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../runtime-inference-optimizations/optimizing-for-latency.html">
     Optimizing for the Latency
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
    <label for="toctree-checkbox-14">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../runtime-inference-optimizations/optimizing-for-latency/model-caching-overview.html">
       Model Caching Overview
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../runtime-inference-optimizations/optimizing-for-throughput.html">
     Optimizing for Throughput
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../runtime-inference-optimizations/advanced-throughput-options.html">
     Advanced Throughput Options
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../runtime-inference-optimizations/further-low-level-implementation.html">
     Further Low-Level Implementation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tuning-utilities.html">
   Tuning Utilities
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tuning-utilities/cross-check-tool.html">
     Cross Check Tool
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../performance-benchmarks.html">
   Performance Benchmarks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../performance-benchmarks/openvino-performance-benchmarks.html">
     Intel® Distribution of OpenVINO™ toolkit Benchmark Results
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
    <label for="toctree-checkbox-17">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../performance-benchmarks/openvino-performance-benchmarks/performance-benchmarks-faq.html">
       Performance Information Frequently Asked Questions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../performance-benchmarks/openvino-performance-benchmarks/model-accuracy-for-int8-fp32.html">
       Model Accuracy and Performance for INT8 and FP32
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../performance-benchmarks/openvino-model-server-performance-benchmarks.html">
     OpenVINO™ Model Server Benchmark Results
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Deploying Inference
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../openvino-deployment-introduction.html">
   Introduction to OpenVINO™ Deployment
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../openvino-runtime-user-guide.html">
   Performing Inference with OpenVINO Runtime
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../openvino-runtime-integrate-application.html">
     Integrate OpenVINO™ with Your Application
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
    <label for="toctree-checkbox-19">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../openvino-runtime-integrate-application/model-representation.html">
       Model Representation in OpenVINO™ Runtime
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../openvino-runtime-integrate-application/inference-request.html">
       OpenVINO™ Inference Request
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../openvino-runtime-integrate-application/python-api-exclusives.html">
       OpenVINO™ Python API Exclusives
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../changing-input-shapes.html">
     Changing Input Shapes
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="../working-with-devices.html">
     Working with devices
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
    <label for="toctree-checkbox-20">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="query-device-properties.html">
       Query Device Properties
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="inference-device-cpu.html">
       CPU Device
      </a>
     </li>
     <li class="toctree-l3 current active has-children">
      <a class="current reference internal" href="#">
       GPU Device
      </a>
      <input checked="" class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
      <label for="toctree-checkbox-21">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="inference-device-gpu/remote-tensor-gpu.html">
         Remote Tensor API of GPU Plugin
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="inference-device-vpu.html">
       VPU Devices
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
      <label for="toctree-checkbox-22">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="inference-device-vpu/myriad-device.html">
         MYRIAD Device
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="inference-device-vpu/hddl-device.html">
         HDDL Device
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="inference-device-gna.html">
       GNA Device
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="inference-device-arm-cpu.html">
       Arm® CPU Device
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../preprocessing.html">
     Preprocessing
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
    <label for="toctree-checkbox-23">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/preprocessing-api-details.html">
       Preprocessing API
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/layout-api-overview.html">
       Layout API Overview
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/preprocessing-use-case.html">
       Preprocessing - Use Case
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../dynamic-shapes.html">
     Dynamic Shapes
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
    <label for="toctree-checkbox-24">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../dynamic-shapes/dynamic-shapes-not-applicable.html">
       When Dynamic Shapes API is Not Applicable
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../automatic-device-selection.html">
     Automatic Device Selection
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
    <label for="toctree-checkbox-25">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../automatic-device-selection/debugging-auto-device.html">
       Debugging Auto-Device Plugin
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../multi-device-execution-mode.html">
     Running on Multiple Devices Simultaneously
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../heterogeneous-execution-mode.html">
     Heterogeneous execution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../performance-hints.html">
     High-level Performance Hints
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../automatic-batching.html">
     Automatic Batching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stateful-models.html">
     Stateful models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../openvino-deployment-guide.html">
   Deploying Your Applications with OpenVINO™
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
  <label for="toctree-checkbox-26">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../openvino-deployment-guide/deployment-manager-tool.html">
     Deploying Your Application with Deployment Manager
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../openvino-deployment-guide/local-distribution.html">
     Libraries for Local Distribution
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../compile-tool.html">
   Compile Tool
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  THE Ecosystem
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../openvino-security-add-on.html">
   OpenVINO™ Security Add-on
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../dl-workbench-overview.html">
   OpenVINO™ Deep Learning Workbench Overview
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/>
  <label for="toctree-checkbox-27">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../dl-workbench-overview/dl-workbench-install.html">
     Installation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/>
    <label for="toctree-checkbox-28">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dl-workbench-overview/dl-workbench-install/dl-workbench-install-prerequisites.html">
       Prerequisites
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../dl-workbench-overview/dl-workbench-install/run-dl-workbench-locally.html">
       Run the DL Workbench Locally
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/>
      <label for="toctree-checkbox-29">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../dl-workbench-overview/dl-workbench-install/run-dl-workbench-locally/dl-workbench-cofigurations.html">
         Advanced DL Workbench Configurations
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../dl-workbench-overview/dl-workbench-install/run-dl-workbench-locally/dl-workbench-docker.html">
         Work with Docker Container
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dl-workbench-overview/dl-workbench-install/run-dl-workbench-in-devcloud.html">
       Run the DL Workbench in the Intel® DevCloud for the Edge
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../dl-workbench-overview/dl-workbench-get-started.html">
     Get Started
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/>
    <label for="toctree-checkbox-30">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dl-workbench-overview/dl-workbench-get-started/dl-workbench-import-model.html">
       Import Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dl-workbench-overview/dl-workbench-get-started/dl-workbench-create-project.html">
       Create Project
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../dl-workbench-overview/dl-workbench-get-started/dl-workbench-resources.html">
       Educational Resources about DL Workbench
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/>
      <label for="toctree-checkbox-31">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../dl-workbench-overview/dl-workbench-get-started/dl-workbench-resources/dl-workbench-key-concepts.html">
         DL Workbench Key Concepts
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../dl-workbench-overview/dl-workbench-tutorials.html">
     Tutorials
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/>
    <label for="toctree-checkbox-32">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Tutorial_Import_YOLO.html">
       Object Detection Model (YOLOv4)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Measure_Accuracy_Object_detection.html">
       Object Detection Model (SSD_mobilenet)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Tutorial_Classification.html">
       Classification Model (mobilenet)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Measure_Accuracy_Classification.html">
       Classification Model (squeezenet)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Tutorial_Instance_Segmentation.html">
       Instance Segmentation Model (mask R-cnn)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Tutorial_Semantic_Segmentation.html">
       Semantic Segmentation Model (deeplab)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Tutorial_Style_Transfer.html">
       Style Transfer Model (fast-nst-onnx)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Tutorial_NLP.html">
       NLP Model (BERT)
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../dl-workbench-overview/dl-workbench-user-guide.html">
     User Guide
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" type="checkbox"/>
    <label for="toctree-checkbox-33">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Select_Models.html">
       Obtain Models
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-34" name="toctree-checkbox-34" type="checkbox"/>
      <label for="toctree-checkbox-34">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_OMZ_Models.html">
         Import Open Model Zoo Models
        </a>
       </li>
       <li class="toctree-l4 has-children">
        <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Original_Model_Import.html">
         Import Original Model
        </a>
        <input class="toctree-checkbox" id="toctree-checkbox-35" name="toctree-checkbox-35" type="checkbox"/>
        <label for="toctree-checkbox-35">
         <i class="fas fa-chevron-down">
         </i>
        </label>
        <ul>
         <li class="toctree-l5">
          <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Tutorial_Import_Original.html">
           Import Original Model Recommendations
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Generate_Datasets.html">
       Obtain Datasets
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-36" name="toctree-checkbox-36" type="checkbox"/>
      <label for="toctree-checkbox-36">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4 has-children">
        <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Dataset_Types.html">
         Dataset Types
        </a>
        <input class="toctree-checkbox" id="toctree-checkbox-37" name="toctree-checkbox-37" type="checkbox"/>
        <label for="toctree-checkbox-37">
         <i class="fas fa-chevron-down">
         </i>
        </label>
        <ul>
         <li class="toctree-l5">
          <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Download_and_Cut_Datasets.html">
           Cut Datasets
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Select_Environment.html">
       Select Environment
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-38" name="toctree-checkbox-38" type="checkbox"/>
      <label for="toctree-checkbox-38">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4 has-children">
        <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Remote_Profiling.html">
         Work with Remote Targets
        </a>
        <input class="toctree-checkbox" id="toctree-checkbox-39" name="toctree-checkbox-39" type="checkbox"/>
        <label for="toctree-checkbox-39">
         <i class="fas fa-chevron-down">
         </i>
        </label>
        <ul>
         <li class="toctree-l5">
          <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Profile_on_Remote_Machine.html">
           Profile on Remote Machine
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Setup_Remote_Target.html">
           Set Up Remote Target
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Add_Remote_Target.html">
           Register Remote Target in DL Workbench
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Remote_Machines.html">
           Manipulate Remote Machines
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Int_8_Quantization.html">
       Optimize Model Performance
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Run_Inference.html">
       Explore Inference Configurations
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-40" name="toctree-checkbox-40" type="checkbox"/>
      <label for="toctree-checkbox-40">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Run_Single_Inference.html">
         Run Inference
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_View_Inference_Results.html">
         View Inference Results
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Compare_Performance_between_Two_Versions_of_Models.html">
         Compare Performance between Two Versions of a Model
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Visualize_Model.html">
         Visualize Model
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Visualize_Accuracy.html">
       Visualize Model Output
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Measure_Accuracy.html">
       Create Accuracy Report
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-41" name="toctree-checkbox-41" type="checkbox"/>
      <label for="toctree-checkbox-41">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Accuracy_Configuration.html">
         Accuracy Configuration
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Configure_Accuracy_Settings.html">
         Set Accuracy Configuration
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Accuracy_Report_Results.html">
         Interpret Accuracy Report Results
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Deployment_Package.html">
       Create Deployment Package
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-42" name="toctree-checkbox-42" type="checkbox"/>
      <label for="toctree-checkbox-42">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Deploy_and_Integrate_Performance_Criteria_into_Application.html">
         Deploy and Integrate Performance Criteria into Application
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Export_Project.html">
       Export Project
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Jupyter_Notebooks_CLI.html">
       Learn OpenVINO in DL Workbench
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-43" name="toctree-checkbox-43" type="checkbox"/>
      <label for="toctree-checkbox-43">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Jupyter_Notebooks.html">
         Learn Model Inference with OpenVINO™ API in JupyterLab Environment
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Persist_Database.html">
       Restore DL Workbench State
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_security_Workbench.html">
       Run DL Workbench Securely
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-44" name="toctree-checkbox-44" type="checkbox"/>
      <label for="toctree-checkbox-44">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Authentication.html">
         Enable Authentication in DL Workbench
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../dl-workbench-overview/_workbench-files-to-migrate/workbench_docs_Workbench_DG_Configure_TLS.html">
         Configure Transport Layer Security (TLS)
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../dl-workbench-overview/dl-workbench-troubleshooting.html">
     Troubleshooting
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-45" name="toctree-checkbox-45" type="checkbox"/>
    <label for="toctree-checkbox-45">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dl-workbench-overview/dl-workbench-troubleshooting/dl-workbench-devcloud-troubleshooting.html">
       Troubleshooting for DL Workbench in the Intel® DevCloud for the Edge
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Media Processing and Computer Vision Libraries
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intel-deep-learning-streamer.html">
   Intel® Deep Learning Streamer
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../opencv-graph-api.html">
   Introduction to OpenCV Graph API
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-46" name="toctree-checkbox-46" type="checkbox"/>
  <label for="toctree-checkbox-46">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../opencv-graph-api/graph-api-kernel.html">
     Graph API Kernel API
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../opencv-graph-api/face-beautification-algorithm.html">
     Implementing a Face Beautification Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../opencv-graph-api/face-analytics-pipeline.html">
     Building a Face Analytics Pipeline
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.opencv.org/master/">
   OpenCV Developer Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://software.intel.com/en-us/openclsdk-devguide">
   OpenCL™ Developer Guide
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  OpenVINO Extensibility
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../openvino-extensibility-mechanism.html">
   OpenVINO Extensibility Mechanism
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-47" name="toctree-checkbox-47" type="checkbox"/>
  <label for="toctree-checkbox-47">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../openvino-extensibility-mechanism/custom-openvino-operations.html">
     Custom OpenVINO™ Operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../openvino-extensibility-mechanism/frontend-extensions.html">
     Frontend Extensions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../openvino-extensibility-mechanism/custom-operations_for_gpu.html">
     How to Implement Custom Operations for GPU
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../openvino-extensibility-mechanism/custom-operations_for_vpu.html">
     How to Implement Custom Operations for VPU (Intel® Neural Compute Stick 2)
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../openvino-extensibility-mechanism/model_optimizer_extensibility.html">
     Model Optimizer Extensibility
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-48" name="toctree-checkbox-48" type="checkbox"/>
    <label for="toctree-checkbox-48">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../openvino-extensibility-mechanism/model_optimizer_extensibility/extending-model-optimizer-with-caffe-python-layers.html">
       Extending Model Optimizer with Caffe Python Layers
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../openvino-transformation-api.html">
   Overview of Transformations API
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-49" name="toctree-checkbox-49" type="checkbox"/>
  <label for="toctree-checkbox-49">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../openvino-transformation-api/transformation-api-model-pass.html">
     OpenVINO Model Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../openvino-transformation-api/transformation-api-matcher-pass.html">
     OpenVINO Matcher Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../openvino-transformation-api/transformation-api-graph-rewrite-pass.html">
     OpenVINO Graph Rewrite Pass
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../openvino-plugin-developer-guide.html">
   Overview of Inference Engine Plugin Library
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-50" name="toctree-checkbox-50" type="checkbox"/>
  <label for="toctree-checkbox-50">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../openvino-plugin-developer-guide/openvino-custom-plugins.html">
     Plugin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../openvino-plugin-developer-guide/executable-network-class-in-custom-plugins.html">
     Executable Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../openvino-plugin-developer-guide/synchronous-inference-request.html">
     Synchronous Inference Request
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../openvino-plugin-developer-guide/asynchronous-inference-request.html">
     Asynchronous Inference Request
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../openvino-plugin-developer-guide/building-custom-plugins-with-cmake.html">
     Build Plugin Using CMake
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../openvino-plugin-developer-guide/testing-custom-openvino-plugins.html">
     Plugin Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../openvino-plugin-developer-guide/quantized_network_support.html">
     Quantized networks compute and restrictions
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../openvino-plugin-developer-guide/low-precision-transformations.html">
     OpenVINO™ Low Precision Transformations
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-51" name="toctree-checkbox-51" type="checkbox"/>
    <label for="toctree-checkbox-51">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../openvino-plugin-developer-guide/low-precision-transformations/low-precision-transformation-attributes.html">
       Low-Precision Transformation Attributes
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-52" name="toctree-checkbox-52" type="checkbox"/>
      <label for="toctree-checkbox-52">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../openvino-plugin-developer-guide/low-precision-transformations/low-precision-transformation-attributes/avgpoolprecisionpreserved.html">
         AvgPoolPrecisionPreserved attribute
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../openvino-plugin-developer-guide/low-precision-transformations/low-precision-transformation-attributes/intervalsalignment.html">
         IntervalsAlignment attribute
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../openvino-plugin-developer-guide/low-precision-transformations/low-precision-transformation-attributes/precisionpreserved.html">
         PrecisionPreserved attribute
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../openvino-plugin-developer-guide/low-precision-transformations/low-precision-transformation-attributes/precisions.html">
         Precisions attribute
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../openvino-plugin-developer-guide/low-precision-transformations/low-precision-transformation-attributes/quantizationalignment.html">
         QuantizationAlignment attribute
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../openvino-plugin-developer-guide/low-precision-transformations/low-precision-transformation-attributes/quantizationgranularity.html">
         QuantizationGranularity attribute
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../openvino-plugin-developer-guide/low-precision-transformations/prerequisites-transformations.html">
       Step 1. Prerequisites Transformations
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../openvino-plugin-developer-guide/low-precision-transformations/markup-transformations.html">
       Step 2. Markup Transformations
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../openvino-plugin-developer-guide/low-precision-transformations/main-transformations.html">
       Step 3. Main Transformations
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../openvino-plugin-developer-guide/low-precision-transformations/cleanup-transformations.html">
       Step 4. Cleanup Transformations
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../openvino-plugin-developer-guide/custom-plugin-api-reference.html">
     Plugin API Reference
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-53" name="toctree-checkbox-53" type="checkbox"/>
    <label for="toctree-checkbox-53">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="simple">
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Use OpenVINO™ Toolkit Securely
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../openvino-security-introduction.html">
   Introduction to OpenVINO™ Security
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../openvino-dl-workbench-security.html">
   Deep Learning Workbench Security
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../using-encrypted-models-with-openvino.html">
   Using Encrypted Models with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../openvino-security-add-on.html">
   OpenVINO™ Security Add-on
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#device-naming-convention">
   Device Naming Convention
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#supported-inference-data-types">
   Supported Inference Data Types
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#supported-features">
   Supported Features
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multi-device-execution">
     Multi-device Execution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#automatic-batching">
     Automatic Batching
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multi-stream-execution">
     Multi-stream Execution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dynamic-shapes">
     Dynamic Shapes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#preprocessing-acceleration">
     Preprocessing Acceleration
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-caching">
     Model Caching
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extensibility">
     Extensibility
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gpu-context-and-memory-sharing-via-remotetensor-api">
     GPU Context and Memory Sharing via RemoteTensor API
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#supported-properties">
   Supported Properties
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#read-write-properties">
     Read-write properties
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#read-only-properties">
     Read-only Properties
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#limitations">
   Limitations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gpu-performance-checklist-summary">
   GPU Performance Checklist: Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#additional-resources">
   Additional Resources
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                <div class="tocsection download-docs">
  <div class="dropdown sst-dropdown">
    <button class="button bttn-prm button-size-m" data-display="static" type="button" id="download-options"
      data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
      Download Docs
    </button>
    <div class="dropdown-menu" aria-labelledby="download-options">
      <a class="dropdown-item" href="#" onclick="window.print()">.pdf</a>
      <a id="download-zip-btn" class="dropdown-item" href="#">.zip</a>
    </div>
  </div>
</div>
              </div>
              
            
          </div>
          

          
          
              
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">

<div class="tocsection editthispage">
    <a href="None">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

            
                <div>
                  
  <span class="target" id="deploy-infer-gpu-device"><span id="index-0"></span></span><section id="gpu-device">
<h1>GPU Device<a class="headerlink" href="#gpu-device" title="Permalink to this headline">¶</a></h1>
<p><span class="target" id="deploy-infer-gpu-device-1md-openvino-docs-ov-runtime-ug-supported-plugins-gpu"></span></p>
<div class="toctree-wrapper compound">
</div>
<p>The GPU plugin is an OpenCL based plugin for inference of deep neural networks
on Intel GPUs, both integrated and discrete ones. For an in-depth description
of the GPU plugin, see:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/openvinotoolkit/openvino/wiki/GPUPluginDevelopersDocs">GPU plugin developers documentation</a></p></li>
<li><p><a class="reference external" href="https://github.com/openvinotoolkit/openvino/tree/master/src/plugins/intel_gpu/">OpenVINO Runtime GPU plugin source files</a></p></li>
<li><p><a class="reference external" href="https://software.intel.com/en-us/articles/accelerating-deep-learning-inference-with-intel-processor-graphics">Accelerate Deep Learning Inference with Intel® Processor Graphics</a>.</p></li>
</ul>
<p>The GPU plugin is a part of the Intel® Distribution of OpenVINO™ toolkit. For
more information on how to configure a system to use it, see the
<a class="reference internal" href="../../../get-started-guide/install-additional-configurations/configuration-for-intel-gpu.html#install-config-gpu"><span class="std std-ref">GPU configuration</span></a>.</p>
<section id="device-naming-convention">
<h2>Device Naming Convention<a class="headerlink" href="#device-naming-convention" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Devices are enumerated as <code class="docutils literal notranslate"><span class="pre">GPU.X</span></code>, where <code class="docutils literal notranslate"><span class="pre">X={0,</span> <span class="pre">1,</span> <span class="pre">2,...}</span></code> (only Intel®
GPU devices are considered).</p></li>
<li><p>If the system has an integrated GPU, its <code class="docutils literal notranslate"><span class="pre">id</span></code> is always 0 (<code class="docutils literal notranslate"><span class="pre">GPU.0</span></code>).</p></li>
<li><p>The order of other GPUs is not predefined and depends on the GPU driver.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">GPU</span></code> is an alias for <code class="docutils literal notranslate"><span class="pre">GPU.0</span></code>.</p></li>
<li><p>If the system does not have an integrated GPU, devices are enumerated,
starting from 0.</p></li>
<li><p>For GPUs with multi-tile architecture (multiple sub-devices in OpenCL terms),
a specific tile may be addressed as <code class="docutils literal notranslate"><span class="pre">GPU.X.Y</span></code>, where <code class="docutils literal notranslate"><span class="pre">X,Y={0,</span> <span class="pre">1,</span> <span class="pre">2,...}</span></code>,
<code class="docutils literal notranslate"><span class="pre">X</span></code> - id of the GPU device, <code class="docutils literal notranslate"><span class="pre">Y</span></code> - id of the tile within device <code class="docutils literal notranslate"><span class="pre">X</span></code></p></li>
</ul>
<p>For demonstration purposes, see the
<a class="reference internal" href="../../../get-started-guide/samples/cpp-sample-hello-query-device.html#get-started-samples-cpp-query-device"><span class="std std-ref">Hello Query Device C++ Sample</span></a>
that can print out the list of available devices with associated indices. Below
is an example output (truncated to the device names only):</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="p">.</span><span class="o">/</span><span class="n">hello_query_device</span>
<span class="n">Available</span> <span class="nl">devices</span><span class="p">:</span>
    <span class="nl">Device</span><span class="p">:</span> <span class="n">CPU</span>
<span class="p">...</span>
    <span class="nl">Device</span><span class="p">:</span> <span class="n">GPU</span><span class="mf">.0</span>
<span class="p">...</span>
    <span class="nl">Device</span><span class="p">:</span> <span class="n">GPU</span><span class="mf">.1</span>
<span class="p">...</span>
    <span class="nl">Device</span><span class="p">:</span> <span class="n">HDDL</span></pre></div></div><p>Then, device name can be passed to the
<code class="docutils literal notranslate"><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core-1a46555f0803e8c29524626be08e7f5c5a"><span class="std std-ref"><span class="pre">ov::Core::compile_model()</span></span></a></code>
method:</p>
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--3-input--1" name="tab-set--3" type="radio"><label class="tab-label" for="tab-set--3-input--1">Running on a default device</label><div class="tab-content docutils">
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--0-input--1" name="tab-set--0" type="radio"><label class="tab-label" for="tab-set--0-input--1">C++</label><div class="tab-content docutils">
<div class="highlight"><div class="highlight"><pre><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core"><span class="std std-ref">ov::Core</span></a><span></span> <span class="n">core</span><span class="p">;</span>
<span class="k">auto</span> <a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga461856fdfb6d7533dc53355aec9e9fad"><span class="std std-ref">model</span></a><span></span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core-1ae0576a95f841c3a6f5e46e4802716981"><span class="std std-ref">read_model</span></a><span></span><span class="p">(</span><span class="s">&quot;model.xml&quot;</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">compiled_model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core-1a46555f0803e8c29524626be08e7f5c5a"><span class="std std-ref">compile_model</span></a><span></span><span class="p">(</span><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga461856fdfb6d7533dc53355aec9e9fad"><span class="std std-ref">model</span></a><span></span><span class="p">,</span> <span class="s">&quot;GPU&quot;</span><span class="p">);</span></pre></div></div></div>
<input class="tab-input" id="tab-set--0-input--2" name="tab-set--0" type="radio"><label class="tab-label" for="tab-set--0-input--2">Python</label><div class="tab-content docutils">
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">core</span> <span class="o">=</span> <span class="n">Core</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><span class="n">read_model</span><span class="p">(</span><span class="s">&quot;model.xml&quot;</span><span class="p">)</span>
<span class="n">compiled_model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><span class="n">compile_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s">&quot;GPU&quot;</span><span class="p">)</span></pre></div></div></div>
</div>
</div>
<input class="tab-input" id="tab-set--3-input--2" name="tab-set--3" type="radio"><label class="tab-label" for="tab-set--3-input--2">Running on a specific GPU</label><div class="tab-content docutils">
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--1-input--1" name="tab-set--1" type="radio"><label class="tab-label" for="tab-set--1-input--1">C++</label><div class="tab-content docutils">
<div class="highlight"><div class="highlight"><pre><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core"><span class="std std-ref">ov::Core</span></a><span></span> <span class="n">core</span><span class="p">;</span>
<span class="k">auto</span> <a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga461856fdfb6d7533dc53355aec9e9fad"><span class="std std-ref">model</span></a><span></span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core-1ae0576a95f841c3a6f5e46e4802716981"><span class="std std-ref">read_model</span></a><span></span><span class="p">(</span><span class="s">&quot;model.xml&quot;</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">compiled_model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core-1a46555f0803e8c29524626be08e7f5c5a"><span class="std std-ref">compile_model</span></a><span></span><span class="p">(</span><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga461856fdfb6d7533dc53355aec9e9fad"><span class="std std-ref">model</span></a><span></span><span class="p">,</span> <span class="s">&quot;GPU.1&quot;</span><span class="p">);</span></pre></div></div></div>
<input class="tab-input" id="tab-set--1-input--2" name="tab-set--1" type="radio"><label class="tab-label" for="tab-set--1-input--2">Python</label><div class="tab-content docutils">
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">core</span> <span class="o">=</span> <span class="n">Core</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><span class="n">read_model</span><span class="p">(</span><span class="s">&quot;model.xml&quot;</span><span class="p">)</span>
<span class="n">compiled_model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><span class="n">compile_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s">&quot;GPU.1&quot;</span><span class="p">)</span></pre></div></div></div>
</div>
</div>
<input class="tab-input" id="tab-set--3-input--3" name="tab-set--3" type="radio"><label class="tab-label" for="tab-set--3-input--3">Running on a specific tile</label><div class="tab-content docutils">
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--2-input--1" name="tab-set--2" type="radio"><label class="tab-label" for="tab-set--2-input--1">C++</label><div class="tab-content docutils">
<div class="highlight"><div class="highlight"><pre><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core"><span class="std std-ref">ov::Core</span></a><span></span> <span class="n">core</span><span class="p">;</span>
<span class="k">auto</span> <a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga461856fdfb6d7533dc53355aec9e9fad"><span class="std std-ref">model</span></a><span></span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core-1ae0576a95f841c3a6f5e46e4802716981"><span class="std std-ref">read_model</span></a><span></span><span class="p">(</span><span class="s">&quot;model.xml&quot;</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">compiled_model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core-1a46555f0803e8c29524626be08e7f5c5a"><span class="std std-ref">compile_model</span></a><span></span><span class="p">(</span><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga461856fdfb6d7533dc53355aec9e9fad"><span class="std std-ref">model</span></a><span></span><span class="p">,</span> <span class="s">&quot;GPU.1.0&quot;</span><span class="p">);</span></pre></div></div></div>
<input class="tab-input" id="tab-set--2-input--2" name="tab-set--2" type="radio"><label class="tab-label" for="tab-set--2-input--2">Python</label><div class="tab-content docutils">
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">core</span> <span class="o">=</span> <span class="n">Core</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><span class="n">read_model</span><span class="p">(</span><span class="s">&quot;model.xml&quot;</span><span class="p">)</span>
<span class="n">compiled_model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><span class="n">compile_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s">&quot;GPU.1.0&quot;</span><span class="p">)</span></pre></div></div></div>
</div>
</div>
</div>
</section>
<section id="supported-inference-data-types">
<h2>Supported Inference Data Types<a class="headerlink" href="#supported-inference-data-types" title="Permalink to this headline">¶</a></h2>
<p>The GPU plugin supports the following data types as inference precision of
internal primitives:</p>
<ul class="simple">
<li><p>Floating-point data types:</p>
<ul>
<li><p>f32</p></li>
<li><p>f16</p></li>
</ul>
</li>
<li><p>Quantized data types:</p>
<ul>
<li><p>u8</p></li>
<li><p>i8</p></li>
<li><p>u1</p></li>
</ul>
</li>
</ul>
<p>Selected precision of each primitive depends on the operation precision in IR,
quantization primitives, and available hardware capabilities. The <code class="docutils literal notranslate"><span class="pre">u1</span></code> /
<code class="docutils literal notranslate"><span class="pre">u8</span></code> / <code class="docutils literal notranslate"><span class="pre">i8</span></code> data types are used for quantized operations only, which means
that they are not selected automatically for non-quantized operations. For more
details on how to get a quantized model, refer to the
<a class="reference internal" href="../../model-optimization-guide.html#optim-perf-model-optim-guide"><span class="std std-ref">Model Optimization guide</span></a>.</p>
<p>Floating-point precision of a GPU primitive is selected based on operation
precision in the OpenVINO IR, except for the
<a class="reference internal" href="../../converting-models-with-model-optimizer/fp16-compression-with-model-optimizer.html#conv-prep-fp16-compression"><span class="std std-ref">compressed f16 OpenVINO IR form</span></a>,
which is executed in the <code class="docutils literal notranslate"><span class="pre">f16</span></code> precision.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Hardware acceleration for <code class="docutils literal notranslate"><span class="pre">i8</span></code> / <code class="docutils literal notranslate"><span class="pre">u8</span></code> precision may be unavailable
on some platforms. In such cases, a model is executed in the floating-point
precision taken from IR. Hardware support of <code class="docutils literal notranslate"><span class="pre">u8</span></code> / <code class="docutils literal notranslate"><span class="pre">i8</span></code> acceleration can
be queried via the <code class="docutils literal notranslate"><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1gadb13d62787fc4485733329f044987294"><span class="std std-ref"><span class="pre">ov::device::capabilities</span></span></a></code>
property.</p>
</div>
<p><a class="reference internal" href="../../../get-started-guide/samples/cpp-sample-hello-query-device.html#get-started-samples-cpp-query-device"><span class="std std-ref">Hello Query Device C++ Sample</span></a>
can be used to print out the supported data types for all detected devices.</p>
</section>
<section id="supported-features">
<h2>Supported Features<a class="headerlink" href="#supported-features" title="Permalink to this headline">¶</a></h2>
<p>The GPU plugin supports the following features:</p>
<section id="multi-device-execution">
<h3>Multi-device Execution<a class="headerlink" href="#multi-device-execution" title="Permalink to this headline">¶</a></h3>
<p>If a system has multiple GPUs (for example, an integrated and a discrete Intel
GPU), then any supported model can be executed on all GPUs simultaneously. It
is done by specifying <code class="docutils literal notranslate"><span class="pre">MULTI:GPU.1,GPU.0</span></code> as a target device.</p>
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--4-input--1" name="tab-set--4" type="radio"><label class="tab-label" for="tab-set--4-input--1">C++</label><div class="tab-content docutils">
<div class="highlight"><div class="highlight"><pre><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core"><span class="std std-ref">ov::Core</span></a><span></span> <span class="n">core</span><span class="p">;</span>
<span class="k">auto</span> <a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga461856fdfb6d7533dc53355aec9e9fad"><span class="std std-ref">model</span></a><span></span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core-1ae0576a95f841c3a6f5e46e4802716981"><span class="std std-ref">read_model</span></a><span></span><span class="p">(</span><span class="s">&quot;model.xml&quot;</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">compiled_model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core-1a46555f0803e8c29524626be08e7f5c5a"><span class="std std-ref">compile_model</span></a><span></span><span class="p">(</span><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga461856fdfb6d7533dc53355aec9e9fad"><span class="std std-ref">model</span></a><span></span><span class="p">,</span> <span class="s">&quot;MULTI:GPU.1,GPU.0&quot;</span><span class="p">);</span></pre></div></div></div>
<input class="tab-input" id="tab-set--4-input--2" name="tab-set--4" type="radio"><label class="tab-label" for="tab-set--4-input--2">Python</label><div class="tab-content docutils">
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">core</span> <span class="o">=</span> <span class="n">Core</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><span class="n">read_model</span><span class="p">(</span><span class="s">&quot;model.xml&quot;</span><span class="p">)</span>
<span class="n">compiled_model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><span class="n">compile_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s">&quot;MULTI:GPU.1,GPU.0&quot;</span><span class="p">)</span></pre></div></div></div>
</div>
<p>For more details, see the <a class="reference internal" href="../multi-device-execution-mode.html#deploy-infer-multi-plugin"><span class="std std-ref">Multi-device execution</span></a>.</p>
</section>
<section id="automatic-batching">
<h3>Automatic Batching<a class="headerlink" href="#automatic-batching" title="Permalink to this headline">¶</a></h3>
<p>The GPU plugin is capable of reporting
<code class="docutils literal notranslate"><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga5dbd8ab0c8a177234cade9a54c96249c"><span class="std std-ref"><span class="pre">ov::max_batch_size</span></span></a></code>
and <code class="docutils literal notranslate"><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga129bad2da2fc2a40a7d746d86fc9c68d"><span class="std std-ref"><span class="pre">ov::optimal_batch_size</span></span></a></code>
metrics with respect to the current hardware platform and model. Therefore,
automatic batching is enabled by default when
<code class="docutils literal notranslate"><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga129bad2da2fc2a40a7d746d86fc9c68d"><span class="std std-ref"><span class="pre">ov::optimal_batch_size</span></span></a></code>
is <code class="docutils literal notranslate"><span class="pre">&gt;</span> <span class="pre">1</span></code> and <code class="docutils literal notranslate"><span class="pre">ov::hint::performance_mode(ov::hint::PerformanceMode::THROUGHPUT)</span></code>
is set. Alternatively, it can be enabled explicitly via the device notion,
for example <code class="docutils literal notranslate"><span class="pre">BATCH:GPU</span></code>.</p>
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--7-input--1" name="tab-set--7" type="radio"><label class="tab-label" for="tab-set--7-input--1">Batching via BATCH plugin</label><div class="tab-content docutils">
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--5-input--1" name="tab-set--5" type="radio"><label class="tab-label" for="tab-set--5-input--1">C++</label><div class="tab-content docutils">
<div class="highlight"><div class="highlight"><pre><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core"><span class="std std-ref">ov::Core</span></a><span></span> <span class="n">core</span><span class="p">;</span>
<span class="k">auto</span> <a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga461856fdfb6d7533dc53355aec9e9fad"><span class="std std-ref">model</span></a><span></span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core-1ae0576a95f841c3a6f5e46e4802716981"><span class="std std-ref">read_model</span></a><span></span><span class="p">(</span><span class="s">&quot;model.xml&quot;</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">compiled_model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core-1a46555f0803e8c29524626be08e7f5c5a"><span class="std std-ref">compile_model</span></a><span></span><span class="p">(</span><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga461856fdfb6d7533dc53355aec9e9fad"><span class="std std-ref">model</span></a><span></span><span class="p">,</span> <span class="s">&quot;BATCH:GPU&quot;</span><span class="p">);</span></pre></div></div></div>
<input class="tab-input" id="tab-set--5-input--2" name="tab-set--5" type="radio"><label class="tab-label" for="tab-set--5-input--2">Python</label><div class="tab-content docutils">
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">core</span> <span class="o">=</span> <span class="n">Core</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><span class="n">read_model</span><span class="p">(</span><span class="s">&quot;model.xml&quot;</span><span class="p">)</span>
<span class="n">compiled_model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><span class="n">compile_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s">&quot;BATCH:GPU&quot;</span><span class="p">)</span></pre></div></div></div>
</div>
</div>
<input class="tab-input" id="tab-set--7-input--2" name="tab-set--7" type="radio"><label class="tab-label" for="tab-set--7-input--2">Batching via throughput hint</label><div class="tab-content docutils">
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--6-input--1" name="tab-set--6" type="radio"><label class="tab-label" for="tab-set--6-input--1">C++</label><div class="tab-content docutils">
<div class="highlight"><div class="highlight"><pre><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core"><span class="std std-ref">ov::Core</span></a><span></span> <span class="n">core</span><span class="p">;</span>
<span class="k">auto</span> <a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga461856fdfb6d7533dc53355aec9e9fad"><span class="std std-ref">model</span></a><span></span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core-1ae0576a95f841c3a6f5e46e4802716981"><span class="std std-ref">read_model</span></a><span></span><span class="p">(</span><span class="s">&quot;model.xml&quot;</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">compiled_model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core-1a46555f0803e8c29524626be08e7f5c5a"><span class="std std-ref">compile_model</span></a><span></span><span class="p">(</span><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga461856fdfb6d7533dc53355aec9e9fad"><span class="std std-ref">model</span></a><span></span><span class="p">,</span> <span class="s">&quot;GPU&quot;</span><span class="p">,</span> <a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga2691fe27acc8aa1d1700ad40b6da3ba2"><span class="std std-ref">ov::hint::performance_mode</span></a><span></span><span class="p">(</span><a class="reference internal" href="../../../../api/groups/enumov_1_1hint_1_1PerformanceMode.html#doxid-group-ov-runtime-cpp-prop-api-1gga032aa530efa40760b79af14913d48d73a50f9b1f40c078d242af7ec323ace44b3"><span class="std std-ref">ov::hint::PerformanceMode::THROUGHPUT</span></a><span></span><span class="p">));</span></pre></div></div></div>
<input class="tab-input" id="tab-set--6-input--2" name="tab-set--6" type="radio"><label class="tab-label" for="tab-set--6-input--2">Python</label><div class="tab-content docutils">
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">core</span> <span class="o">=</span> <span class="n">Core</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><span class="n">read_model</span><span class="p">(</span><span class="s">&quot;model.xml&quot;</span><span class="p">)</span>
<span class="n">compiled_model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><span class="n">compile_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s">&quot;GPU&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s">&quot;PERFORMANCE_HINT&quot;</span><span class="o">:</span> <span class="s">&quot;THROUGHPUT&quot;</span><span class="p">})</span></pre></div></div></div>
</div>
</div>
</div>
<p>For more details, see the <a class="reference internal" href="../automatic-batching.html#deploy-infer-automatic-batching"><span class="std std-ref">Automatic batching</span></a>.</p>
</section>
<section id="multi-stream-execution">
<h3>Multi-stream Execution<a class="headerlink" href="#multi-stream-execution" title="Permalink to this headline">¶</a></h3>
<p>If either the <code class="docutils literal notranslate"><span class="pre">ov::num_streams(n_streams)</span></code> with <code class="docutils literal notranslate"><span class="pre">n_streams</span> <span class="pre">&gt;</span> <span class="pre">1</span></code> or the
<code class="docutils literal notranslate"><span class="pre">ov::hint::performance_mode(ov::hint::PerformanceMode::THROUGHPUT)</span></code> property
is set for the GPU plugin, multiple streams are created for the model. In the
case of GPU plugin each stream has its own host thread and an associated OpenCL
queue which means that the incoming infer requests can be processed simultaneously.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Simultaneous scheduling of kernels to different queues does not mean
that the kernels are actually executed in parallel on the GPU device. The
actual behavior depends on the hardware architecture and in some cases the
execution may be serialized inside the GPU driver.</p>
</div>
<p>When multiple inferences of the same model need to be executed in parallel, the
multi-stream feature is preferred to multiple instances of the model or
application. The reason for this is that the implementation of streams in the
GPU plugin supports weight memory sharing across streams, thus, memory
consumption may be lower, compared to the other approaches.</p>
<p>For more details, see the <a class="reference internal" href="../../runtime-inference-optimizations.html#optim-perf-runtime-inference-optim"><span class="std std-ref">optimization guide</span></a>.</p>
</section>
<section id="dynamic-shapes">
<h3>Dynamic Shapes<a class="headerlink" href="#dynamic-shapes" title="Permalink to this headline">¶</a></h3>
<p>The GPU plugin supports dynamic shapes for batch dimension only (specified as
<code class="docutils literal notranslate"><span class="pre">N</span></code> in the <a class="reference internal" href="../preprocessing/layout-api-overview.html#deploy-infer-layout-api-overview"><span class="std std-ref">layouts terms</span></a>)
with a fixed upper bound. Any other dynamic dimensions are unsupported. Internally,
GPU plugin creates <code class="docutils literal notranslate"><span class="pre">log2(N)</span></code> (<code class="docutils literal notranslate"><span class="pre">N</span></code> - is an upper bound for batch dimension
here) low-level execution graphs for batch sizes equal to powers of 2 to emulate
dynamic behavior, so that incoming infer request with a specific batch size is
executed via a minimal combination of internal networks. For example, batch size
33 may be executed via 2 internal networks with batch size 32 and 1.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Such approach requires much more memory and the overall model compilation
time is significantly longer, compared to the static batch scenario.</p>
</div>
<p>The code snippet below demonstrates how to use dynamic batching in simple scenarios:</p>
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--8-input--1" name="tab-set--8" type="radio"><label class="tab-label" for="tab-set--8-input--1">C++</label><div class="tab-content docutils">
<div class="highlight"><div class="highlight"><pre><span></span><span class="c1">// Read model</span>
<a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core"><span class="std std-ref">ov::Core</span></a><span></span> <span class="n">core</span><span class="p">;</span>
<span class="k">auto</span> <a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga461856fdfb6d7533dc53355aec9e9fad"><span class="std std-ref">model</span></a><span></span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core-1ae0576a95f841c3a6f5e46e4802716981"><span class="std std-ref">read_model</span></a><span></span><span class="p">(</span><span class="s">&quot;model.xml&quot;</span><span class="p">);</span>

<a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga461856fdfb6d7533dc53355aec9e9fad"><span class="std std-ref">model</span></a><span></span><span class="o">-&gt;</span><span class="n">reshape</span><span class="p">({{</span><a class="reference internal" href="../../../../api/groups/classov_1_1Dimension.html#doxid-classov-1-1-dimension"><span class="std std-ref">ov::Dimension</span></a><span></span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <a class="reference internal" href="../../../../api/groups/classov_1_1Dimension.html#doxid-classov-1-1-dimension"><span class="std std-ref">ov::Dimension</span></a><span></span><span class="p">(</span>C<span></span><span class="p">),</span> <a class="reference internal" href="../../../../api/groups/classov_1_1Dimension.html#doxid-classov-1-1-dimension"><span class="std std-ref">ov::Dimension</span></a><span></span><span class="p">(</span>H<span></span><span class="p">),</span> <a class="reference internal" href="../../../../api/groups/classov_1_1Dimension.html#doxid-classov-1-1-dimension"><span class="std std-ref">ov::Dimension</span></a><span></span><span class="p">(</span>W<span></span><span class="p">)}});</span>  <span class="c1">// {1..10, C, H, W}</span>

<span class="c1">// compile model and create infer request</span>
<span class="k">auto</span> <span class="n">compiled_model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core-1a46555f0803e8c29524626be08e7f5c5a"><span class="std std-ref">compile_model</span></a><span></span><span class="p">(</span><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga461856fdfb6d7533dc53355aec9e9fad"><span class="std std-ref">model</span></a><span></span><span class="p">,</span> <span class="s">&quot;GPU&quot;</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">infer_request</span> <span class="o">=</span> <span class="n">compiled_model</span><span class="p">.</span><a class="reference internal" href="../../../../api/groups/classov_1_1CompiledModel.html#doxid-classov-1-1-compiled-model-1ae3633c0eb5173ed776446fba32b95953"><span class="std std-ref">create_infer_request</span></a><span></span><span class="p">();</span>
<span class="k">auto</span> <span class="n">input</span> <span class="o">=</span> <a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga461856fdfb6d7533dc53355aec9e9fad"><span class="std std-ref">model</span></a><span></span><span class="o">-&gt;</span><span class="n">get_parameters</span><span class="p">().</span><span class="n">at</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>

<span class="c1">// ...</span>

<span class="c1">// create input tensor with specific batch size</span>
<a class="reference internal" href="../../../../api/groups/classov_1_1Tensor.html#doxid-classov-1-1-tensor"><span class="std std-ref">ov::Tensor</span></a><span></span> <span class="n">input_tensor</span><span class="p">(</span><span class="n">input</span><span class="o">-&gt;</span><span class="n">get_element_type</span><span class="p">(),</span> <span class="p">{</span><span class="mi">2</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">});</span>

<span class="c1">// ...</span>

<span class="n">infer_request</span><span class="p">.</span><span class="n">set_tensor</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">);</span>
<span class="n">infer_request</span><span class="p">.</span><span class="n">infer</span><span class="p">();</span></pre></div></div></div>
<input class="tab-input" id="tab-set--8-input--2" name="tab-set--8" type="radio"><label class="tab-label" for="tab-set--8-input--2">Python</label><div class="tab-content docutils">
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">core</span> <span class="o">=</span> <a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core"><span class="std std-ref">ov.Core</span></a><span></span><span class="p">()</span>

<span class="n">C</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">H</span> <span class="o">=</span> <span class="mi">224</span>
<span class="n">W</span> <span class="o">=</span> <span class="mi">224</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><span class="n">read_model</span><span class="p">(</span><span class="s">&quot;model.xml&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">reshape</span><span class="p">([(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">])</span>

<span class="cp"># compile model and create infer request</span>
<span class="n">compiled_model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><span class="n">compile_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s">&quot;GPU&quot;</span><span class="p">)</span>
<span class="n">infer_request</span> <span class="o">=</span> <span class="n">compiled_model</span><span class="p">.</span><span class="n">create_infer_request</span><span class="p">()</span>

<span class="cp"># create input tensor with specific batch size</span>
<span class="n">input_tensor</span> <span class="o">=</span> <a class="reference internal" href="../../../../api/groups/classov_1_1Tensor.html#doxid-classov-1-1-tensor"><span class="std std-ref">ov.Tensor</span></a><span></span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">input</span><span class="p">().</span><span class="n">element_type</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">])</span>

<span class="cp"># ...</span>

<span class="n">infer_request</span><span class="p">.</span><span class="n">infer</span><span class="p">([</span><span class="n">input_tensor</span><span class="p">])</span></pre></div></div></div>
</div>
<p>For more details, see the <a class="reference internal" href="../dynamic-shapes.html#deploy-infer-dynamic-shapes"><span class="std std-ref">dynamic shapes guide</span></a>.</p>
</section>
<section id="preprocessing-acceleration">
<h3>Preprocessing Acceleration<a class="headerlink" href="#preprocessing-acceleration" title="Permalink to this headline">¶</a></h3>
<p>The GPU plugin has the following additional preprocessing options:</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><a class="reference internal" href="../../../../api/groups/groupov_runtime_ocl_gpu_prop_cpp_api.html#doxid-group-ov-runtime-ocl-gpu-prop-cpp-api-1gaec0856a3b996876371138961269b742d"><span class="std std-ref"><span class="pre">ov::intel_gpu::memory_type::surface</span></span></a></code> and <code class="docutils literal notranslate"><span class="pre">ov::intel_gpu::memory_type::buffer</span></code> values for the <code class="docutils literal notranslate"><a class="reference internal" href="../../../../api/groups/classov_1_1preprocess_1_1InputTensorInfo.html#doxid-classov-1-1preprocess-1-1-input-tensor-info-1ad838f8c41ba0ab450b72fec5e2ebf808"><span class="std std-ref"><span class="pre">ov::preprocess::InputTensorInfo::set_memory_type()</span></span></a></code> preprocessing method. These values are intended to be used to provide a hint for the plugin on the type of input Tensors that will be set in runtime to generate proper kernels.</p></li>
</ul>
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--9-input--1" name="tab-set--9" type="radio"><label class="tab-label" for="tab-set--9-input--1">C++</label><div class="tab-content docutils">
<div class="highlight"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="k">namespace</span> <a class="reference internal" href="../../../../api/groups/namespaceov_1_1preprocess.html#doxid-namespaceov-1-1preprocess"><span class="std std-ref">ov::preprocess</span></a><span></span><span class="p">;</span>
<span class="k">auto</span> <span class="n">p</span> <span class="o">=</span> <span class="n">PrePostProcessor</span><span class="p">(</span><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga461856fdfb6d7533dc53355aec9e9fad"><span class="std std-ref">model</span></a><span></span><span class="p">);</span>
<span class="n">p</span><span class="p">.</span><span class="n">input</span><span class="p">().</span><span class="n">tensor</span><span class="p">().</span><span class="n">set_element_type</span><span class="p">(</span><a class="reference internal" href="../../../../api/groups/groupov_element_cpp_api.html#doxid-group-ov-element-cpp-api-1gaaf60c536d3e295285f6a899eb3d29e2f"><span class="std std-ref">ov::element::u8</span></a><span></span><span class="p">)</span>
                  <span class="p">.</span><span class="n">set_color_format</span><span class="p">(</span><a class="reference internal" href="../../../../api/groups/enumov_1_1preprocess_1_1ColorFormat.html#doxid-namespaceov-1-1preprocess-1ab027f26e58038e454e1b50a5243f1707a54f60c652650de96e9d118187b3ba25f"><span class="std std-ref">ov::preprocess::ColorFormat::NV12_TWO_PLANES</span></a><span></span><span class="p">,</span> <span class="p">{</span><span class="s">&quot;y&quot;</span><span class="p">,</span> <span class="s">&quot;uv&quot;</span><span class="p">})</span>
                  <span class="p">.</span><span class="n">set_memory_type</span><span class="p">(</span><a class="reference internal" href="../../../../api/groups/groupov_runtime_ocl_gpu_prop_cpp_api.html#doxid-group-ov-runtime-ocl-gpu-prop-cpp-api-1gaec0856a3b996876371138961269b742d"><span class="std std-ref">ov::intel_gpu::memory_type::surface</span></a><span></span><span class="p">);</span>
<span class="n">p</span><span class="p">.</span><span class="n">input</span><span class="p">().</span><span class="n">preprocess</span><span class="p">().</span><span class="n">convert_color</span><span class="p">(</span><a class="reference internal" href="../../../../api/groups/enumov_1_1preprocess_1_1ColorFormat.html#doxid-namespaceov-1-1preprocess-1ab027f26e58038e454e1b50a5243f1707a2ad5640ebdec72fc79531d1778c6c2dc"><span class="std std-ref">ov::preprocess::ColorFormat::BGR</span></a><span></span><span class="p">);</span>
<span class="n">p</span><span class="p">.</span><span class="n">input</span><span class="p">().</span><span class="n">model</span><span class="p">().</span><span class="n">set_layout</span><span class="p">(</span><span class="s">&quot;NCHW&quot;</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">model_with_preproc</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="n">build</span><span class="p">();</span></pre></div></div></div>
<input class="tab-input" id="tab-set--9-input--2" name="tab-set--9" type="radio"><label class="tab-label" for="tab-set--9-input--2">Python</label><div class="tab-content docutils">
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">from</span> <span class="n">openvino</span><span class="p">.</span><span class="n">runtime</span> <span class="n">import</span> <span class="n">Core</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Layout</span>
<span class="n">from</span> <span class="n">openvino</span><span class="p">.</span><span class="n">preprocess</span> <span class="n">import</span> <span class="n">PrePostProcessor</span><span class="p">,</span> <span class="n">ColorFormat</span>

<span class="n">core</span> <span class="o">=</span> <span class="n">Core</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><span class="n">read_model</span><span class="p">(</span><span class="s">&quot;model.xml&quot;</span><span class="p">)</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">PrePostProcessor</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">p</span><span class="p">.</span><span class="n">input</span><span class="p">().</span><span class="n">tensor</span><span class="p">().</span><span class="n">set_element_type</span><span class="p">(</span><span class="n">Type</span><span class="p">.</span><span class="n">u8</span><span class="p">)</span> \
                  <span class="p">.</span><span class="n">set_color_format</span><span class="p">(</span><span class="n">ColorFormat</span><span class="p">.</span><span class="n">NV12_TWO_PLANES</span><span class="p">,</span> <span class="p">[</span><span class="s">&quot;y&quot;</span><span class="p">,</span> <span class="s">&quot;uv&quot;</span><span class="p">])</span> \
                  <span class="p">.</span><span class="n">set_memory_type</span><span class="p">(</span><span class="s">&quot;GPU_SURFACE&quot;</span><span class="p">)</span>
<span class="n">p</span><span class="p">.</span><span class="n">input</span><span class="p">().</span><span class="n">preprocess</span><span class="p">().</span><span class="n">convert_color</span><span class="p">(</span><span class="n">ColorFormat</span><span class="p">.</span><span class="n">BGR</span><span class="p">)</span>
<span class="n">p</span><span class="p">.</span><span class="n">input</span><span class="p">().</span><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga461856fdfb6d7533dc53355aec9e9fad"><span class="std std-ref">model</span></a><span></span><span class="p">().</span><a class="reference internal" href="../../../../api/groups/groupov_layout_cpp_api.html#doxid-group-ov-layout-cpp-api-1ga18464fb8ed029acb5fdc2bb1737358d9"><span class="std std-ref">set_layout</span></a><span></span><span class="p">(</span><a class="reference internal" href="../../../../api/groups/enumInferenceEngine_1_1Layout.html#doxid-namespace-inference-engine-1a246d143abc5ca07da8d2cadeeb88fdb8"><span class="std std-ref">Layout</span></a><span></span><span class="p">(</span><span class="s">&quot;NCHW&quot;</span><span class="p">))</span>
<span class="n">model_with_preproc</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="n">build</span><span class="p">()</span></pre></div></div></div>
</div>
<p>With such preprocessing, GPU plugin will expect
<code class="docutils literal notranslate"><a class="reference internal" href="../../../../api/groups/classov_1_1intel_gpu_1_1ocl_1_1ClImage2DTensor.html#doxid-classov-1-1intel-gpu-1-1ocl-1-1-cl-image2-d-tensor"><span class="std std-ref"><span class="pre">ov::intel_gpu::ocl::ClImage2DTensor</span></span></a></code>
(or derived) to be passed for each NV12 plane via
<code class="docutils literal notranslate"><a class="reference internal" href="../../../../api/groups/classov_1_1InferRequest.html#doxid-classov-1-1-infer-request-1af54f126e7fb3b3a0343841dda8bcc368"><span class="std std-ref"><span class="pre">ov::InferRequest::set_tensor()</span></span></a></code>
or <code class="docutils literal notranslate"><a class="reference internal" href="../../../../api/groups/classov_1_1InferRequest.html#doxid-classov-1-1-infer-request-1a935a952c07cc7130a64614d0952db997"><span class="std std-ref"><span class="pre">ov::InferRequest::set_tensors()</span></span></a></code>
methods.</p>
<p>For usage examples, refer to the <a class="reference internal" href="inference-device-gpu/remote-tensor-gpu.html#deploy-infer-gpu-device-remote-tensor"><span class="std std-ref">RemoteTensor API</span></a>.</p>
<p>For more details, see the <a class="reference internal" href="../preprocessing.html#deploy-infer-preprocessing-overview"><span class="std std-ref">preprocessing API</span></a>.</p>
</section>
<section id="model-caching">
<h3>Model Caching<a class="headerlink" href="#model-caching" title="Permalink to this headline">¶</a></h3>
<p>Cache for the GPU plugin may be enabled via the common OpenVINO
<code class="docutils literal notranslate"><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga3276fc4ed7cc7d0bbdcf0ae12063728d"><span class="std std-ref"><span class="pre">ov::cache_dir</span></span></a></code>
property. GPU plugin implementation supports only caching of compiled kernels,
so all plugin-specific model transformations are executed on each
<code class="docutils literal notranslate"><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core-1a46555f0803e8c29524626be08e7f5c5a"><span class="std std-ref"><span class="pre">ov::Core::compile_model()</span></span></a></code>
call regardless of the <code class="docutils literal notranslate"><span class="pre">cache_dir</span></code> option. Still, since kernel compilation
is a bottleneck in the model loading process, a significant load time reduction
can be achieved with the <code class="docutils literal notranslate"><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga3276fc4ed7cc7d0bbdcf0ae12063728d"><span class="std std-ref"><span class="pre">ov::cache_dir</span></span></a></code>
property enabled.</p>
<p>For more details, see the <a class="reference internal" href="../../runtime-inference-optimizations/optimizing-for-latency/model-caching-overview.html#optim-perf-model-caching"><span class="std std-ref">Model caching overview</span></a>.</p>
</section>
<section id="extensibility">
<h3>Extensibility<a class="headerlink" href="#extensibility" title="Permalink to this headline">¶</a></h3>
<p>For information on this subject, see the
<a class="reference internal" href="../../openvino-extensibility-mechanism/custom-operations_for_gpu.html#extensibility-gpu"><span class="std std-ref">GPU Extensibility</span></a>.</p>
</section>
<section id="gpu-context-and-memory-sharing-via-remotetensor-api">
<h3>GPU Context and Memory Sharing via RemoteTensor API<a class="headerlink" href="#gpu-context-and-memory-sharing-via-remotetensor-api" title="Permalink to this headline">¶</a></h3>
<p>For information on this subject, see the
<a class="reference internal" href="inference-device-gpu/remote-tensor-gpu.html#deploy-infer-gpu-device-remote-tensor"><span class="std std-ref">RemoteTensor API of GPU Plugin</span></a>.</p>
</section>
</section>
<section id="supported-properties">
<h2>Supported Properties<a class="headerlink" href="#supported-properties" title="Permalink to this headline">¶</a></h2>
<p>The plugin supports the properties listed below.</p>
<section id="read-write-properties">
<h3>Read-write properties<a class="headerlink" href="#read-write-properties" title="Permalink to this headline">¶</a></h3>
<p>All parameters must be set before calling
<code class="docutils literal notranslate"><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core-1a46555f0803e8c29524626be08e7f5c5a"><span class="std std-ref"><span class="pre">ov::Core::compile_model()</span></span></a></code>
in order to take effect or passed as additional argument to
<code class="docutils literal notranslate"><a class="reference internal" href="../../../../api/groups/classov_1_1Core.html#doxid-classov-1-1-core-1a46555f0803e8c29524626be08e7f5c5a"><span class="std std-ref"><span class="pre">ov::Core::compile_model()</span></span></a></code>.</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga3276fc4ed7cc7d0bbdcf0ae12063728d"><span class="std std-ref">ov::cache_dir</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1gafc5bef2fc2b5cfb5a0709cfb04346438"><span class="std std-ref">ov::enable_profiling</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga3663a3976ff7c4bdc3ccdb9ce44945ce"><span class="std std-ref">ov::hint::model_priority</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga2691fe27acc8aa1d1700ad40b6da3ba2"><span class="std std-ref">ov::hint::performance_mode</span></a></p></li>
<li><p>ov::hint::num_requests</p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1gad605a888f3c9b7598ab55023fbf44240"><span class="std std-ref">ov::hint::inference_precision</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga6c63a0223565f650475450fdb466bc0c"><span class="std std-ref">ov::num_streams</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga91555d2fad22aa802aa9d36698805755"><span class="std std-ref">ov::compilation_num_threads</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga433b8ea52e99c2b1fa8b26453485d75d"><span class="std std-ref">ov::device::id</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_ocl_gpu_prop_cpp_api.html#doxid-group-ov-runtime-ocl-gpu-prop-cpp-api-1ga1650ac020ec6e9ea8d03f898ef454e43"><span class="std std-ref">ov::intel_gpu::hint::host_task_priority</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_ocl_gpu_prop_cpp_api.html#doxid-group-ov-runtime-ocl-gpu-prop-cpp-api-1ga41a9b0bfa860966128952ebfcca324b9"><span class="std std-ref">ov::intel_gpu::hint::queue_priority</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_ocl_gpu_prop_cpp_api.html#doxid-group-ov-runtime-ocl-gpu-prop-cpp-api-1gace6031a0761c1917aa84135fe2163d56"><span class="std std-ref">ov::intel_gpu::hint::queue_throttle</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_ocl_gpu_prop_cpp_api.html#doxid-group-ov-runtime-ocl-gpu-prop-cpp-api-1ga2d18d0f9e29ddde42b95d523405ae322"><span class="std std-ref">ov::intel_gpu::enable_loop_unrolling</span></a></p></li>
</ul>
</section>
<section id="read-only-properties">
<h3>Read-only Properties<a class="headerlink" href="#read-only-properties" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga097f1274f26f3f4e1aa4fc3928748592"><span class="std std-ref">ov::supported_properties</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1gac4d3e86ef4fc43b1a80ec28c7be39ef1"><span class="std std-ref">ov::available_devices</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga3549425153790834c212d905b8216196"><span class="std std-ref">ov::range_for_async_infer_requests</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga8a5d84196f6873729167aa512c34a94a"><span class="std std-ref">ov::range_for_streams</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga129bad2da2fc2a40a7d746d86fc9c68d"><span class="std std-ref">ov::optimal_batch_size</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1ga5dbd8ab0c8a177234cade9a54c96249c"><span class="std std-ref">ov::max_batch_size</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1gaabacd9ea113b966be7b53b1d70fd6f42"><span class="std std-ref">ov::device::full_name</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1gaf9b20fd37487c1f525e68c6e0567f1f1"><span class="std std-ref">ov::device::type</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1gae233c458317f6ae508b887eb09308c4c"><span class="std std-ref">ov::device::gops</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_cpp_prop_api.html#doxid-group-ov-runtime-cpp-prop-api-1gadb13d62787fc4485733329f044987294"><span class="std std-ref">ov::device::capabilities</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_ocl_gpu_prop_cpp_api.html#doxid-group-ov-runtime-ocl-gpu-prop-cpp-api-1ga4545149544127b7f82b5d673b8a5a017"><span class="std std-ref">ov::intel_gpu::device_total_mem_size</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_ocl_gpu_prop_cpp_api.html#doxid-group-ov-runtime-ocl-gpu-prop-cpp-api-1ga55179d37180f123686ab43b27ed3f2c9"><span class="std std-ref">ov::intel_gpu::uarch_version</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_ocl_gpu_prop_cpp_api.html#doxid-group-ov-runtime-ocl-gpu-prop-cpp-api-1ga86642bacd4b0fa7f803c212e72318d79"><span class="std std-ref">ov::intel_gpu::execution_units_count</span></a></p></li>
<li><p><a class="reference internal" href="../../../../api/groups/groupov_runtime_ocl_gpu_prop_cpp_api.html#doxid-group-ov-runtime-ocl-gpu-prop-cpp-api-1ga2364c38776f270d5b9560e745fd8ff80"><span class="std std-ref">ov::intel_gpu::memory_statistics</span></a></p></li>
</ul>
</section>
</section>
<section id="limitations">
<h2>Limitations<a class="headerlink" href="#limitations" title="Permalink to this headline">¶</a></h2>
<p>In some cases, the GPU plugin may implicitly execute several primitives on CPU
using internal implementations, which may lead to an increase in CPU utilization.
Below is a list of such operations:</p>
<ul class="simple">
<li><p>Proposal</p></li>
<li><p>NonMaxSuppression</p></li>
<li><p>DetectionOutput</p></li>
</ul>
<p>The behavior depends on specific parameters of the operations and hardware configuration.</p>
</section>
<section id="gpu-performance-checklist-summary">
<span id="gpu-checklist"></span><h2>GPU Performance Checklist: Summary<a class="headerlink" href="#gpu-performance-checklist-summary" title="Permalink to this headline">¶</a></h2>
<p>Since OpenVINO relies on the OpenCL kernels for the GPU implementation, many
general OpenCL tips apply:</p>
<ul class="simple">
<li><p>Prefer <code class="docutils literal notranslate"><span class="pre">FP16</span></code> inference precision over <code class="docutils literal notranslate"><span class="pre">FP32</span></code>, as Model Optimizer can
generate both variants, and the <code class="docutils literal notranslate"><span class="pre">FP32</span></code> is the default. Also, consider using
the <a class="reference external" href="https://docs.openvino.ai/latest/pot_introduction.html">Post-training Optimization Tool</a>.</p></li>
<li><p>Try to group individual infer jobs by using
<a class="reference internal" href="../automatic-batching.html#deploy-infer-automatic-batching"><span class="std std-ref">automatic batching</span></a>.</p></li>
<li><p>Consider <a class="reference internal" href="../../runtime-inference-optimizations/optimizing-for-latency/model-caching-overview.html#optim-perf-model-caching"><span class="std std-ref">caching</span></a>
to minimize model load time.</p></li>
<li><p>If your application performs inference on the CPU alongside the GPU, or otherwise
loads the host heavily, make sure that the OpenCL driver threads do not starve.
<a class="reference internal" href="inference-device-cpu.html#deploy-infer-cpu-device"><span class="std std-ref">CPU configuration options</span></a>
can be used to limit the number of inference threads for the CPU plugin.</p></li>
<li><p>Even in the GPU-only scenario, a GPU driver might occupy a CPU core with
spin-loop polling for completion. If CPU load is a concern, consider the
dedicated <code class="docutils literal notranslate"><span class="pre">queue_throttle</span></code> property mentioned previously. Note that this
option may increase inference latency, so consider combining it with multiple
GPU streams or <a class="reference internal" href="../performance-hints.html#deploy-infer-performance-hints"><span class="std std-ref">throughput performance hints</span></a>.</p></li>
<li><p>When operating media inputs, consider
<a class="reference internal" href="inference-device-gpu/remote-tensor-gpu.html#deploy-infer-gpu-device-remote-tensor"><span class="std std-ref">remote tensors API of the GPU Plugin</span></a>.</p></li>
</ul>
</section>
<section id="additional-resources">
<h2>Additional Resources<a class="headerlink" href="#additional-resources" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="../../../resources/record-of-openvino-supported-devices.html#resources-supp-devices"><span class="std std-ref">Supported Devices</span></a></p></li>
<li><p><a class="reference internal" href="../../performance-optimization.html#optim-perf-introduction"><span class="std std-ref">Optimization guide</span></a></p></li>
<li><p><a class="reference external" href="https://github.com/openvinotoolkit/openvino/wiki/GPUPluginDevelopersDocs">GPU plugin developers documentation</a></p></li>
</ul>
</section>
</section>


                </div>
            
            
                <div class='prev-next-bottom'>
                  
    <a class='button bttn-sec button-size-l' id="prev-link" href="inference-device-cpu.html" title="previous page">Prev</a>
    <a class='button bttn-sec button-size-l' id="next-link" href="inference-device-gpu/remote-tensor-gpu.html" title="next page">Next</a>

                </div>
            
          </main>
          

      </div>
    </div>
  
  <script src="../../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Intel®.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>